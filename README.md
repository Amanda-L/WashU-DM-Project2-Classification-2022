# Washu_datamining_project_2_2022
Project 2: Implemented various models (KNN, SVM, Decision Tree, Random Forest, ANN, Na√Øve Bayes Classifier) with dimension reduction techniques for binary and multiclass classification tasks.

# Information on the files

## Programming Assignment 2.pdf: 

I have a dataset of 20,000 samples of 26 alphabets with each alphabet having 16 features that describe how the alphabet consists of. I separated the dataset into 4 kinds. i.e., pair 1 with only H and K letters, pair 2 with only M and Y letters, pair 3 with only A and B letters, and lastly all letters. 

In the problem, I cluster each pair of datasets with different models. I compare different models in terms of their performance. By looking at the appearance of letters, I have a pre-sense of how certain letters are harder to classify. For instance, D and Q would make models harder to classify apart. I also tried clustering after dimension reduction, to see whether reducing features dimension impacts the results.

## SP2023 Project 2.ipynb and Project 2 Final Report.pdf: 
the jupyter notebook wrote to generate outcomes and process data. 

##
